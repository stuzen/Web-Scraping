# Web-Scraping
I have done quite a bit of gathering in the past, but generally I used API for it, so it was easier.  API allows users to obtain clearly defined kinds of data quickly, by requesting it directly from the database underlying a particular website. What if you have to scrape data from an ancient government website? A website with no modern conventions, data lives in HTML nested frames, with annoying pop-up windows? This was the case when I was tasked with collecting property information such as owner name, sale date, price, grantee information in my job.  After a few unsuccessful attempts with Scrapy, Requests, I came across a great library called Selenium. This library was exactly what I needed as it enables me to interact with the website in every possible way you can think of. You can fill out forms, click buttons, close &switch windows, and of course extract data.

![image](https://user-images.githubusercontent.com/66323880/117584157-41026580-b0d9-11eb-8e1a-6cb1b7f2dd68.png)
